# --- å¼ºåˆ¶å®‰è£…ä¾èµ– (Magic Patch) ---
import subprocess
import sys

def install_packages():
    packages = [
        "langchain", "langchain-community", "langchain-huggingface",
        "faiss-cpu", "sentence-transformers", "huggingface-hub"
    ]
    for package in packages:
        try:
            __import__(package.replace("-", "_"))
        except ImportError:
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])

install_packages()
# --------------------------------
import streamlit as st
from PyPDF2 import PdfReader
from openai import OpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ ‡é¢˜
st.title("ğŸ¤– ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹ (My Knowledge Bot)")

# å·¦ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ“„ æ–‡æ¡£ä¸Šä¼ ")
    
    # æ–‡ä»¶ä¸Šä¼ å™¨
    uploaded_file = st.file_uploader(
        "ä¸Šä¼  PDF æ–‡æ¡£",
        type=["pdf"],
        help="æ”¯æŒä¸Šä¼  PDF æ ¼å¼çš„æ–‡æ¡£"
    )
    
    # æç¤ºæ–‡å­—
    st.caption("è¯·ä¸Šä¼ ä½ çš„æ–‡æ¡£ï¼Œæˆ‘ä¼šåŸºäºå®ƒå›ç­”é—®é¢˜ã€‚")
    
    # å¦‚æœä¸Šä¼ äº†æ–‡ä»¶ï¼Œæ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
    if uploaded_file is not None:
        st.success(f"âœ… å·²ä¸Šä¼ : {uploaded_file.name}")
        st.info(f"æ–‡ä»¶å¤§å°: {uploaded_file.size / 1024:.2f} KB")

# ä¸»åŒºåŸŸ
st.divider()

# ä» Streamlit Secrets è¯»å– API Key
try:
    api_key = st.secrets["DEEPSEEK_API_KEY"]
except KeyError:
    api_key = None
    st.error("âš ï¸ ç®¡ç†å‘˜æœªé…ç½®å¯†é’¥")

# PDF è§£æå’Œå‘é‡åŒ–é€»è¾‘
if uploaded_file is not None:
    try:
        with st.spinner("æ­£åœ¨åˆ†ææ–‡æ¡£..."):
            # è¯»å– PDF æ–‡ä»¶
            pdf_reader = PdfReader(uploaded_file)
            
            # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()
            
            # æ–‡æœ¬åˆ‡ç‰‡
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50
            )
            chunks = text_splitter.split_text(text)
            
            # å‘é‡åŒ–
            embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2"
            )
            
            # åˆ›å»ºå‘é‡ç´¢å¼•
            vectorstore = FAISS.from_texts(chunks, embeddings)
            
            # ä¿å­˜åˆ° session_stateï¼Œé˜²æ­¢åˆ·æ–°ä¸¢å¤±
            st.session_state.vectorstore = vectorstore
            
            # æ˜¾ç¤ºæˆåŠŸæç¤º
            st.success(f"âœ… æˆåŠŸå»ºç«‹ç´¢å¼•ï¼æ–‡æ¡£å·²åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªç‰‡æ®µã€‚")
    
    except Exception as e:
        st.error(f"âŒ å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")

# æ˜¾ç¤ºå†å²èŠå¤©è®°å½•
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# èŠå¤©è¾“å…¥æ¡†
user_question = st.chat_input("å‘æ–‡æ¡£æé—®...")

# RAG é—®ç­”é€»è¾‘ï¼ˆå‘é‡æ£€ç´¢æ¨¡å¼ï¼‰
if user_question:
    # æ£€æŸ¥ API Key
    if not api_key:
        st.warning("âš ï¸ ç®¡ç†å‘˜æœªé…ç½®å¯†é’¥")
    # æ£€æŸ¥å‘é‡åº“æ˜¯å¦å­˜åœ¨
    elif "vectorstore" not in st.session_state:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å¹¶è§£æ PDF æ–‡æ¡£")
    else:
        try:
            # ä¿å­˜ç”¨æˆ·é—®é¢˜åˆ°å†å²è®°å½•
            st.session_state.messages.append({"role": "user", "content": user_question})
            
            # æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
            with st.chat_message("user"):
                st.write(user_question)
            
            # å‘é‡æ£€ç´¢ï¼šæ‰¾å‡ºæœ€ç›¸å…³çš„ 3 ä¸ªç‰‡æ®µ
            vectorstore = st.session_state.vectorstore
            relevant_chunks = vectorstore.similarity_search(user_question, k=3)
            
            # æ„å»º Contextï¼šæ‹¼æ¥æ£€ç´¢åˆ°çš„ç‰‡æ®µ
            context = "\n\n".join([chunk.page_content for chunk in relevant_chunks])
            
            # æ„å»º Prompt
            prompt = f"åŸºäºä»¥ä¸‹å‚è€ƒç‰‡æ®µå›ç­”é—®é¢˜ï¼š\n\n{context}\n\né—®é¢˜ï¼š{user_question}"
            
            # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆé€‚é… DeepSeekï¼‰
            client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com"
            )
            
            # è°ƒç”¨ DeepSeek API
            with st.chat_message("assistant"):
                with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­..."):
                    response = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "user", "content": prompt}
                        ]
                    )
                
                # è·å– AI å›ç­”
                ai_answer = response.choices[0].message.content
                
                # æ˜¾ç¤º AI å›ç­”
                st.write(ai_answer)
            
            # ä¿å­˜ AI å›ç­”åˆ°å†å²è®°å½•
            st.session_state.messages.append({"role": "assistant", "content": ai_answer})
            
        except Exception as e:
            st.error(f"âŒ è°ƒç”¨ API æ—¶å‡ºé”™: {str(e)}")

