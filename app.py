import streamlit as st
import json
import re
import pandas as pd
from PyPDF2 import PdfReader
from openai import OpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ ‡é¢˜
st.title("ğŸ¤– ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹ (My Knowledge Bot)")

# å·¦ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ“„ æ–‡æ¡£ä¸Šä¼ ")
    
    # æ–‡ä»¶ä¸Šä¼ å™¨
    uploaded_file = st.file_uploader(
        "ä¸Šä¼  PDF æ–‡æ¡£",
        type=["pdf"],
        help="æ”¯æŒä¸Šä¼  PDF æ ¼å¼çš„æ–‡æ¡£"
    )
    
    # æç¤ºæ–‡å­—
    st.caption("è¯·ä¸Šä¼ ä½ çš„æ–‡æ¡£ï¼Œæˆ‘ä¼šåŸºäºå®ƒå›ç­”é—®é¢˜ã€‚")
    
    # å¦‚æœä¸Šä¼ äº†æ–‡ä»¶ï¼Œæ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
    if uploaded_file is not None:
        st.success(f"âœ… å·²ä¸Šä¼ : {uploaded_file.name}")
        st.info(f"æ–‡ä»¶å¤§å°: {uploaded_file.size / 1024:.2f} KB")

# ä¸»åŒºåŸŸ
st.divider()

# ä» Streamlit Secrets è¯»å– API Key
try:
    api_key = st.secrets["DEEPSEEK_API_KEY"]
except KeyError:
    api_key = None
    st.error("âš ï¸ ç®¡ç†å‘˜æœªé…ç½®å¯†é’¥")

# PDF è§£æå’Œå‘é‡åŒ–é€»è¾‘
if uploaded_file is not None:
    try:
        with st.spinner("æ­£åœ¨åˆ†ææ–‡æ¡£..."):
            # è¯»å– PDF æ–‡ä»¶
            pdf_reader = PdfReader(uploaded_file)
            
            # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()
            
            # æ–‡æœ¬åˆ‡ç‰‡
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50,  # <--- åŠ ä¸Šè¿™ä¸ªï¼
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ"] # å°½é‡åœ¨å¥å·å¤„åˆ‡åˆ†
            )
            chunks = text_splitter.split_text(text)
            
            # å‘é‡åŒ–
            embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2"
            )
            
            # åˆ›å»ºå‘é‡ç´¢å¼•
            vectorstore = FAISS.from_texts(chunks, embeddings)
            
            # ä¿å­˜åˆ° session_stateï¼Œé˜²æ­¢åˆ·æ–°ä¸¢å¤±
            st.session_state.vectorstore = vectorstore
            
            # æ˜¾ç¤ºæˆåŠŸæç¤º
            st.success(f"âœ… æˆåŠŸå»ºç«‹ç´¢å¼•ï¼æ–‡æ¡£å·²åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªç‰‡æ®µã€‚")
    
    except Exception as e:
        st.error(f"âŒ å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")

# ç»“æ„åŒ–æ•°æ®æå–åŠŸèƒ½
if "vectorstore" in st.session_state and api_key:
    st.divider()
    st.subheader("ğŸ“Š ç»“æ„åŒ–æ•°æ®æå–")
    
    if st.button("ğŸ” ä¸€é”®æå–å…³é”®äº‹ä»¶è¡¨", type="primary"):
        try:
            # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
            client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com"
            )
            
            # ä½¿ç”¨ RAG æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µï¼ˆæ£€ç´¢æ›´å¤šç‰‡æ®µä»¥è·å–å®Œæ•´ä¿¡æ¯ï¼‰
            vectorstore = st.session_state.vectorstore
            # æ£€ç´¢æ›´å¤šç‰‡æ®µä»¥è·å–å®Œæ•´çš„äº‹ä»¶ä¿¡æ¯
            relevant_chunks = vectorstore.similarity_search("å…³é”®äº‹ä»¶ é£é™© åº”å¯¹æªæ–½", k=10)
            
            # æ„å»º Context
            context = "\n\n".join([chunk.page_content for chunk in relevant_chunks])
            
            # æ„å»ºç»“æ„åŒ–æå–çš„ System Prompt
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®æå–åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»æ–‡æ¡£ä¸­æå–å…³é”®äº‹ä»¶ä¿¡æ¯ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„ JSON æ ¼å¼è¾“å‡ºã€‚

è¦æ±‚ï¼š
1. ä»”ç»†åˆ†ææ–‡æ¡£å†…å®¹ï¼Œè¯†åˆ«æ‰€æœ‰å…³é”®äº‹ä»¶
2. ä¸ºæ¯ä¸ªäº‹ä»¶è¯„ä¼°é£é™©ç­‰çº§ï¼ˆé«˜/ä¸­/ä½ï¼‰
3. æå–æ ¸å¿ƒåº”å¯¹æªæ–½ï¼ˆä¸è¶…è¿‡20å­—ï¼‰
4. è®°å½•äº‹ä»¶æ‰€åœ¨çš„é¡µç ï¼ˆå¦‚æœæ–‡æ¡£ä¸­æœ‰é¡µç ä¿¡æ¯ï¼‰

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- å¿…é¡»è¾“å‡ºçº¯ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½• Markdown ä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—
- ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON Schema è¾“å‡ºï¼š

{
  "events": [
    {
      "event_name": "äº‹ä»¶åç§°",
      "risk_level": "é«˜/ä¸­/ä½",
      "key_action": "æ ¸å¿ƒåº”å¯¹æªæ–½(ä¸è¶…è¿‡20å­—)",
      "page_ref": é¡µç æ•°å­—æˆ–null
    }
  ]
}

å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰äº‹ä»¶ä¿¡æ¯ï¼Œè¿”å›ç©ºæ•°ç»„ï¼š{"events": []}"""

            user_prompt = f"è¯·ä»ä»¥ä¸‹æ–‡æ¡£å†…å®¹ä¸­æå–å…³é”®äº‹ä»¶ä¿¡æ¯ï¼š\n\n{context}"
            
            with st.spinner("ğŸ” æ­£åœ¨æå–å…³é”®äº‹ä»¶..."):
                # è°ƒç”¨ APIï¼Œæœ€å¤šé‡è¯•3æ¬¡
                max_retries = 3
                json_data = None
                
                for attempt in range(max_retries):
                    try:
                        response = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=[
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": user_prompt}
                            ],
                            temperature=0.1  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
                        )
                        
                        # è·å–å“åº”å†…å®¹
                        raw_response = response.choices[0].message.content.strip()
                        
                        # æ¸…ç†å¯èƒ½çš„ Markdown ä»£ç å—æ ‡è®°
                        raw_response = re.sub(r'```json\s*', '', raw_response)
                        raw_response = re.sub(r'```\s*', '', raw_response)
                        raw_response = raw_response.strip()
                        
                        # å°è¯•è§£æ JSON
                        json_data = json.loads(raw_response)
                        break  # æˆåŠŸè§£æï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                        
                    except json.JSONDecodeError as e:
                        if attempt < max_retries - 1:
                            st.warning(f"âš ï¸ JSON è§£æå¤±è´¥ï¼Œæ­£åœ¨é‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                            continue
                        else:
                            st.error(f"âŒ JSON è§£æå¤±è´¥ï¼š{str(e)}")
                            st.code(raw_response, language="text")
                            raise
                    except Exception as e:
                        if attempt < max_retries - 1:
                            st.warning(f"âš ï¸ æå–å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                            continue
                        else:
                            raise
            
            # æ˜¾ç¤ºæå–ç»“æœ
            if json_data and "events" in json_data and len(json_data["events"]) > 0:
                st.success(f"âœ… æˆåŠŸæå– {len(json_data['events'])} ä¸ªå…³é”®äº‹ä»¶ï¼")
                
                # è½¬æ¢ä¸º DataFrame æ ¼å¼
                events_list = json_data["events"]
                
                # ä½¿ç”¨ st.dataframe æ˜¾ç¤ºè¡¨æ ¼
                df = pd.DataFrame(events_list)
                
                # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåºï¼Œä½¿å…¶æ›´æ˜“è¯»
                if "page_ref" in df.columns:
                    df = df[["event_name", "risk_level", "key_action", "page_ref"]]
                else:
                    df = df[["event_name", "risk_level", "key_action"]]
                
                # é‡å‘½ååˆ—åä¸ºä¸­æ–‡
                df.columns = ["äº‹ä»¶åç§°", "é£é™©ç­‰çº§", "æ ¸å¿ƒåº”å¯¹æªæ–½", "é¡µç "] if "page_ref" in df.columns else ["äº‹ä»¶åç§°", "é£é™©ç­‰çº§", "æ ¸å¿ƒåº”å¯¹æªæ–½"]
                
                # æ˜¾ç¤ºè¡¨æ ¼
                st.dataframe(df, use_container_width=True, hide_index=True)
                
                # æ˜¾ç¤ºåŸå§‹ JSONï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•ï¼‰
                with st.expander("ğŸ“‹ æŸ¥çœ‹åŸå§‹ JSON æ•°æ®"):
                    st.json(json_data)
            else:
                st.info("â„¹ï¸ æœªåœ¨æ–‡æ¡£ä¸­å‘ç°å…³é”®äº‹ä»¶ä¿¡æ¯ã€‚")
                
        except Exception as e:
            st.error(f"âŒ æå–è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

# æ˜¾ç¤ºå†å²èŠå¤©è®°å½•
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# èŠå¤©è¾“å…¥æ¡†
user_question = st.chat_input("å‘æ–‡æ¡£æé—®...")

# RAG é—®ç­”é€»è¾‘ï¼ˆå‘é‡æ£€ç´¢æ¨¡å¼ï¼‰
if user_question:
    # æ£€æŸ¥ API Key
    if not api_key:
        st.warning("âš ï¸ ç®¡ç†å‘˜æœªé…ç½®å¯†é’¥")
    # æ£€æŸ¥å‘é‡åº“æ˜¯å¦å­˜åœ¨
    elif "vectorstore" not in st.session_state:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å¹¶è§£æ PDF æ–‡æ¡£")
    else:
        try:
            # ä¿å­˜ç”¨æˆ·é—®é¢˜åˆ°å†å²è®°å½•
            st.session_state.messages.append({"role": "user", "content": user_question})
            
            # æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
            with st.chat_message("user"):
                st.write(user_question)
            
            # å‘é‡æ£€ç´¢ï¼šæ‰¾å‡ºæœ€ç›¸å…³çš„ 3 ä¸ªç‰‡æ®µ
            vectorstore = st.session_state.vectorstore
            relevant_chunks = vectorstore.similarity_search(user_question, k=3)
            
            # æ„å»º Contextï¼šæ‹¼æ¥æ£€ç´¢åˆ°çš„ç‰‡æ®µ
            context = "\n\n".join([chunk.page_content for chunk in relevant_chunks])
            
            # æ„å»º Prompt
            prompt = f"åŸºäºä»¥ä¸‹å‚è€ƒç‰‡æ®µå›ç­”é—®é¢˜ï¼š\n\n{context}\n\né—®é¢˜ï¼š{user_question}"
            
            # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆé€‚é… DeepSeekï¼‰
            client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com"
            )
            
            # è°ƒç”¨ DeepSeek API
            with st.chat_message("assistant"):
                with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­..."):
                    response = client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "user", "content": prompt}
                        ]
                    )
                
                # è·å– AI å›ç­”
                ai_answer = response.choices[0].message.content
                
                # æ˜¾ç¤º AI å›ç­”
                st.write(ai_answer)
            
            # æ˜¾ç¤ºæ¥æºç‰‡æ®µï¼ˆåœ¨ AI å›ç­”ä¸‹æ–¹ï¼‰
            with st.expander("ğŸ” æŸ¥çœ‹ AI å‚è€ƒçš„æ–‡æ¡£ç‰‡æ®µ (Source Context)"):
                for i, chunk in enumerate(relevant_chunks, 1):
                    st.markdown(f"**ç‰‡æ®µ {i}:**")
                    st.info(chunk.page_content)
                    if i < len(relevant_chunks):
                        st.markdown("---")
            
            # ä¿å­˜ AI å›ç­”åˆ°å†å²è®°å½•
            st.session_state.messages.append({"role": "assistant", "content": ai_answer})
            
        except Exception as e:
            st.error(f"âŒ è°ƒç”¨ API æ—¶å‡ºé”™: {str(e)}")

